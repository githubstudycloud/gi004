# éŸ³è‰²æå–ä¸TTSè¯­éŸ³ç”Ÿæˆæ–¹æ¡ˆ

æœ¬é¡¹ç›®æ¢ç©¶ä½¿ç”¨ Python ä»éŸ³é¢‘ä¸­æå–éŸ³è‰²ç‰¹å¾ï¼Œå¹¶ç»“åˆ ChatTTS ç­‰æ¨¡å‹ç”Ÿæˆè¯­éŸ³çš„æŠ€æœ¯æ–¹æ¡ˆã€‚

## ğŸ“‹ ç›®å½•

- [æ–¹æ¡ˆæ¦‚è¿°](#æ–¹æ¡ˆæ¦‚è¿°)
- [æ–¹æ¡ˆä¸€ï¼šChatTTS + Speaker Embedding](#æ–¹æ¡ˆä¸€chattts--speaker-embedding)
- [æ–¹æ¡ˆäºŒï¼šOpenVoice éŸ³è‰²å…‹éš†](#æ–¹æ¡ˆäºŒopenvoice-éŸ³è‰²å…‹éš†)
- [æ–¹æ¡ˆä¸‰ï¼šCoqui TTS + XTTS-v2](#æ–¹æ¡ˆä¸‰coqui-tts--xtts-v2)
- [æ–¹æ¡ˆå››ï¼šSpeechBrain + ChatTTS ç»„åˆ](#æ–¹æ¡ˆå››speechbrain--chattts-ç»„åˆ)
- [æ–¹æ¡ˆå¯¹æ¯”](#æ–¹æ¡ˆå¯¹æ¯”)
- [å®‰è£…æŒ‡å—](#å®‰è£…æŒ‡å—)

---

## æ–¹æ¡ˆæ¦‚è¿°

éŸ³è‰²å…‹éš† TTS çš„æ ¸å¿ƒæµç¨‹ï¼š

```
å‚è€ƒéŸ³é¢‘ â†’ éŸ³è‰²ç‰¹å¾æå–(Speaker Embedding) â†’ TTSæ¨¡å‹ â†’ ç”Ÿæˆç›®æ ‡éŸ³é¢‘
```

### å…³é”®æŠ€æœ¯ç‚¹

1. **Speaker Embeddingï¼ˆè¯´è¯äººåµŒå…¥ï¼‰**ï¼šå°†è¯´è¯äººçš„å£°éŸ³ç‰¹å¾ç¼–ç ä¸ºä¸€ä¸ªå‘é‡
2. **Tone Color Converterï¼ˆéŸ³è‰²è½¬æ¢å™¨ï¼‰**ï¼šå°†ç”Ÿæˆçš„è¯­éŸ³è½¬æ¢ä¸ºç›®æ ‡éŸ³è‰²
3. **Zero-shot Voice Cloningï¼ˆé›¶æ ·æœ¬è¯­éŸ³å…‹éš†ï¼‰**ï¼šä»…éœ€å‡ ç§’å‚è€ƒéŸ³é¢‘å³å¯å…‹éš†

---

## æ–¹æ¡ˆä¸€ï¼šChatTTS + Speaker Embedding

### ç®€ä»‹

[ChatTTS](https://github.com/2noise/chattts) æ˜¯ä¸€ä¸ªä¸“ä¸ºæ—¥å¸¸å¯¹è¯è®¾è®¡çš„ç”Ÿæˆå¼è¯­éŸ³æ¨¡å‹ï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼ŒéŸ³è´¨è‡ªç„¶æµç•…ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- âœ… æ”¯æŒç»†ç²’åº¦éŸµå¾‹æ§åˆ¶ï¼ˆç¬‘å£°ã€åœé¡¿ç­‰ï¼‰
- âœ… ä¸­è‹±æ–‡æ··åˆæ”¯æŒè‰¯å¥½
- âœ… å¯ä¿å­˜å’ŒåŠ è½½ speaker embedding (.ptæ–‡ä»¶)
- âš ï¸ ä¸æ”¯æŒç›´æ¥ä»éŸ³é¢‘æå–éŸ³è‰²ï¼ˆéœ€é…åˆå…¶ä»–å·¥å…·ï¼‰

### éŸ³è‰²ä½¿ç”¨æ–¹å¼

```python
import ChatTTS
import torch

# åˆå§‹åŒ–
chat = ChatTTS.Chat()
chat.load(compile=False)

# æ–¹å¼1: éšæœºé‡‡æ ·è¯´è¯äºº
rand_spk = chat.sample_random_speaker()
print(rand_spk)  # ä¿å­˜æ­¤å€¼ä»¥ä¾¿å¤ç”¨

# æ–¹å¼2: åŠ è½½é¢„ä¿å­˜çš„ .pt éŸ³è‰²æ–‡ä»¶
spk = torch.load("speaker_embedding.pt", map_location="cpu")

# è®¾ç½®æ¨ç†å‚æ•°
params_infer_code = ChatTTS.Chat.InferCodeParams(
    spk_emb=spk,        # è¯´è¯äººåµŒå…¥
    temperature=0.3,     # æ¸©åº¦å‚æ•°
    top_P=0.7,
    top_K=20,
)

# ç”Ÿæˆè¯­éŸ³
wavs = chat.infer(
    ["ä½ å¥½ï¼Œè¿™æ˜¯ä¸€æ®µæµ‹è¯•è¯­éŸ³ã€‚"],
    params_infer_code=params_infer_code,
)
```

### éŸ³è‰²æ–‡ä»¶æ¥æº

1. **ChatTTS_Speaker é¡¹ç›®**ï¼šæä¾›é¢„è®­ç»ƒçš„ç¨³å®šéŸ³è‰²ç§å­
   - GitHub: https://github.com/6drf21e/ChatTTS_Speaker
2. **è‡ªè¡Œé‡‡æ ·ä¿å­˜**ï¼šä½¿ç”¨ `sample_random_speaker()` é‡‡æ ·æ»¡æ„çš„éŸ³è‰²åä¿å­˜

### å±€é™æ€§

ChatTTS æœ¬èº«**ä¸æ”¯æŒä»ä»»æ„éŸ³é¢‘æå–éŸ³è‰²**ï¼Œéœ€è¦é…åˆæ–¹æ¡ˆå››ä¸­çš„ SpeechBrain ç­‰å·¥å…·ã€‚

---

## æ–¹æ¡ˆäºŒï¼šOpenVoice éŸ³è‰²å…‹éš†

### ç®€ä»‹

[OpenVoice](https://github.com/myshell-ai/OpenVoice) æ˜¯ MIT å’Œ MyShell å¼€å‘çš„å³æ—¶è¯­éŸ³å…‹éš†æ¨¡å‹ï¼Œæ”¯æŒä»ä»»æ„éŸ³é¢‘æå–éŸ³è‰²ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- âœ… **çœŸæ­£çš„éŸ³è‰²å…‹éš†**ï¼šå¯ä»ä»»æ„éŸ³é¢‘æå–éŸ³è‰²
- âœ… åªéœ€å‡ ç§’å‚è€ƒéŸ³é¢‘
- âœ… æ”¯æŒå¤šè¯­è¨€
- âœ… MIT å¼€æºè®¸å¯ï¼Œå¯å•†ç”¨
- âœ… åˆ†ç¦»éŸ³è‰²å’Œè¯­è¨€/å£éŸ³æ§åˆ¶

### å·¥ä½œåŸç†

```
å‚è€ƒéŸ³é¢‘ â†’ SE Extractor â†’ Tone Color Embedding
                                    â†“
æ–‡æœ¬ â†’ Base TTS â†’ åŸºç¡€è¯­éŸ³ â†’ Tone Color Converter â†’ ç›®æ ‡éŸ³è‰²è¯­éŸ³
```

### ä»£ç ç¤ºä¾‹

```python
import os
import torch
from openvoice import se_extractor
from openvoice.api import ToneColorConverter

# è®¾å¤‡é…ç½®
device = "cuda:0" if torch.cuda.is_available() else "cpu"

# åŠ è½½éŸ³è‰²è½¬æ¢å™¨
ckpt_converter = 'checkpoints_v2/converter'
tone_color_converter = ToneColorConverter(
    f'{ckpt_converter}/config.json',
    device=device
)
tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')

# 1. ä»å‚è€ƒéŸ³é¢‘æå–éŸ³è‰²
reference_audio = 'reference_speaker.mp3'
target_se, audio_name = se_extractor.get_se(
    reference_audio,
    tone_color_converter,
    vad=True  # å¯ç”¨è¯­éŸ³æ´»åŠ¨æ£€æµ‹
)

# 2. åŠ è½½æºéŸ³è‰²ï¼ˆåŸºç¡€TTSçš„éŸ³è‰²ï¼‰
source_se = torch.load(f'{ckpt_converter}/ses/base_se.pth', map_location=device)

# 3. éŸ³è‰²è½¬æ¢
tone_color_converter.convert(
    audio_src_path='generated_base.wav',  # åŸºç¡€TTSç”Ÿæˆçš„éŸ³é¢‘
    src_se=source_se,
    tgt_se=target_se,
    output_path='output_cloned.wav'
)
```

### å®‰è£…

```bash
git clone https://github.com/myshell-ai/OpenVoice.git
cd OpenVoice
pip install -e .

# ä¸‹è½½æ¨¡å‹æ£€æŸ¥ç‚¹
# V2ç‰ˆæœ¬: https://huggingface.co/myshell-ai/OpenVoiceV2
```

---

## æ–¹æ¡ˆä¸‰ï¼šCoqui TTS + XTTS-v2

### ç®€ä»‹

[Coqui TTS](https://github.com/coqui-ai/TTS) æ˜¯åŠŸèƒ½æœ€å…¨é¢çš„å¼€æº TTS å·¥å…·åŒ…ï¼ŒXTTS-v2 æ”¯æŒé›¶æ ·æœ¬è¯­éŸ³å…‹éš†ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- âœ… åŠŸèƒ½å…¨é¢ï¼Œæ”¯æŒå¤šç§ TTS æ¨¡å‹
- âœ… XTTS-v2 æ”¯æŒ 17 ç§è¯­è¨€
- âœ… åªéœ€ 6 ç§’å‚è€ƒéŸ³é¢‘
- âœ… å†…ç½® Speaker Encoder
- âš ï¸ æ³¨æ„ï¼šCoqui å…¬å¸å·²å…³é—­ï¼Œä½†å¼€æºé¡¹ç›®ä»å¯ç”¨

### ä»£ç ç¤ºä¾‹

```python
from TTS.api import TTS

# åˆå§‹åŒ– XTTS-v2 æ¨¡å‹
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2", gpu=True)

# ç›´æ¥ä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œè¯­éŸ³å…‹éš†
tts.tts_to_file(
    text="ä½ å¥½ï¼Œè¿™æ˜¯å…‹éš†åçš„è¯­éŸ³ã€‚",
    file_path="output.wav",
    speaker_wav="reference_speaker.wav",  # å‚è€ƒéŸ³é¢‘
    language="zh-cn"
)
```

### æå– Speaker Embedding

```python
from TTS.utils.synthesizer import Synthesizer
from TTS.tts.utils.speakers import SpeakerManager

# ä½¿ç”¨ Speaker Encoder æå–åµŒå…¥
speaker_manager = SpeakerManager(
    encoder_model_path="path/to/encoder_model.pth",
    encoder_config_path="path/to/encoder_config.json"
)

# ä»éŸ³é¢‘è®¡ç®— embedding
embedding = speaker_manager.compute_embedding_from_clip("reference.wav")
```

### å®‰è£…

```bash
pip install TTS

# æˆ–ä»æºç å®‰è£…
git clone https://github.com/coqui-ai/TTS
cd TTS
pip install -e .
```

---

## æ–¹æ¡ˆå››ï¼šSpeechBrain + ChatTTS ç»„åˆ

### ç®€ä»‹

ç»“åˆ [SpeechBrain](https://speechbrain.github.io/) çš„è¯´è¯äººç¼–ç å™¨æå–éŸ³è‰²ç‰¹å¾ï¼Œå†ç”¨äº ChatTTS ç­‰æ¨¡å‹ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- âœ… SpeechBrain æä¾›é«˜è´¨é‡çš„ Speaker Embedding
- âœ… å¯ä¸å¤šç§ TTS æ¨¡å‹ç»„åˆ
- âœ… çµæ´»æ€§é«˜
- âš ï¸ éœ€è¦é¢å¤–çš„åµŒå…¥ç©ºé—´æ˜ å°„

### ä»£ç ç¤ºä¾‹

```python
from speechbrain.inference.speaker import EncoderClassifier
import torch

# åŠ è½½é¢„è®­ç»ƒçš„è¯´è¯äººç¼–ç å™¨
classifier = EncoderClassifier.from_hparams(
    source="speechbrain/spkrec-ecapa-voxceleb",
    savedir="pretrained_models/spkrec-ecapa-voxceleb"
)

# ä»éŸ³é¢‘æå– embedding
embedding = classifier.encode_file("reference_speaker.wav")
print(f"Embedding shape: {embedding.shape}")  # [1, 192]

# ä¿å­˜ embedding
torch.save(embedding, "speaker_embedding.pt")

# è®¡ç®—ä¸¤ä¸ªéŸ³é¢‘çš„ç›¸ä¼¼åº¦
emb1 = classifier.encode_file("speaker1.wav")
emb2 = classifier.encode_file("speaker2.wav")
similarity = torch.nn.functional.cosine_similarity(emb1, emb2)
print(f"Similarity: {similarity.item()}")
```

### ä¸ ChatTTS ç»“åˆï¼ˆå®éªŒæ€§ï¼‰

```python
# æ³¨æ„ï¼šè¿™éœ€è¦è¿›è¡ŒåµŒå…¥ç©ºé—´çš„æ˜ å°„ï¼Œå› ä¸ºä¸¤è€…çš„ embedding ç»´åº¦ä¸åŒ
# ChatTTS ä½¿ç”¨è‡ªå·±çš„ speaker embedding æ ¼å¼

# æ–¹æ³•1ï¼šè®­ç»ƒä¸€ä¸ªæ˜ å°„ç½‘ç»œ
# æ–¹æ³•2ï¼šä½¿ç”¨ ChatTTS çš„éŸ³è‰²ç§å­åº“åŒ¹é…æœ€ç›¸ä¼¼çš„éŸ³è‰²
```

### å®‰è£…

```bash
pip install speechbrain
```

---

## æ–¹æ¡ˆäº”ï¼špyannote-audio éŸ³è‰²åˆ†æ

### ç®€ä»‹

[pyannote-audio](https://github.com/pyannote/pyannote-audio) ä¸“æ³¨äºè¯´è¯äººåˆ†æï¼Œå¯ç”¨äºéŸ³è‰²ç‰¹å¾æå–ã€‚

### ä»£ç ç¤ºä¾‹

```python
from pyannote.audio import Model, Inference

# åŠ è½½è¯´è¯äººåµŒå…¥æ¨¡å‹
model = Model.from_pretrained(
    "pyannote/embedding",
    use_auth_token="YOUR_HF_TOKEN"
)

# åˆ›å»ºæ¨ç†å™¨
inference = Inference(model, window="whole")

# æå– embedding
embedding = inference("reference_speaker.wav")
print(f"Embedding shape: {embedding.shape}")
```

---

## æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | éŸ³è‰²æå– | TTSè´¨é‡ | ä¸­æ–‡æ”¯æŒ | æ˜“ç”¨æ€§ | æ¨èåœºæ™¯ |
|------|---------|---------|---------|--------|---------|
| **ChatTTS** | âŒ ä¸æ”¯æŒ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | ä¸­æ–‡å¯¹è¯TTS |
| **OpenVoice** | âœ… æ”¯æŒ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | **æ¨èï¼šéŸ³è‰²å…‹éš†** |
| **Coqui XTTS** | âœ… æ”¯æŒ | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | å¤šè¯­è¨€å…‹éš† |
| **SpeechBrain** | âœ… æ”¯æŒ | N/A | N/A | â­â­â­ | éŸ³è‰²åˆ†æ/è¯†åˆ« |

### æ¨èç»„åˆ

1. **æœ€ç®€å•**ï¼šOpenVoiceï¼ˆç«¯åˆ°ç«¯éŸ³è‰²å…‹éš†ï¼‰
2. **ä¸­æ–‡æœ€ä½³**ï¼šOpenVoice æå–éŸ³è‰² + ChatTTS ç”Ÿæˆ
3. **å¤šè¯­è¨€**ï¼šCoqui XTTS-v2

---

## å®‰è£…æŒ‡å—

### ç¯å¢ƒè¦æ±‚

- Python 3.9+
- PyTorch 2.0+
- CUDA 11.8+ï¼ˆæ¨èGPUåŠ é€Ÿï¼‰

### å¿«é€Ÿå®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n voice-clone python=3.10
conda activate voice-clone

# å®‰è£…åŸºç¡€ä¾èµ–
pip install torch torchaudio

# å®‰è£…å„æ–¹æ¡ˆä¾èµ–
pip install chattts        # ChatTTS
pip install TTS            # Coqui TTS
pip install speechbrain    # SpeechBrain

# OpenVoice éœ€è¦ä»æºç å®‰è£…
git clone https://github.com/myshell-ai/OpenVoice.git
cd OpenVoice && pip install -e .
```

---

## å‚è€ƒèµ„æº

- [ChatTTS GitHub](https://github.com/2noise/chattts)
- [OpenVoice GitHub](https://github.com/myshell-ai/OpenVoice)
- [Coqui TTS GitHub](https://github.com/coqui-ai/TTS)
- [SpeechBrain](https://speechbrain.github.io/)
- [pyannote-audio](https://github.com/pyannote/pyannote-audio)
- [ChatTTS_Speaker éŸ³è‰²åº“](https://github.com/6drf21e/ChatTTS_Speaker)

---

## License

æœ¬æ–‡æ¡£åŠç¤ºä¾‹ä»£ç é‡‡ç”¨ MIT è®¸å¯è¯ã€‚
